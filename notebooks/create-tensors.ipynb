{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.spatial.distance as sd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load models\n",
    "semantic_models = dict()\n",
    "for i in range(1800,2000,10):\n",
    "    data = dict()\n",
    "    vocab = pickle.load(open(str(i) + \"-vocab.pkl\",\"rb\"))\n",
    "    vectors = np.load(str(i) + \"-w.npy\")\n",
    "    data['name'] = i\n",
    "    data['vocab'] = vocab\n",
    "    data['vectors'] = vectors\n",
    "    semantic_models[i] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_neighbors(word,model):\n",
    "    vectors = semantic_models[model]['vectors']\n",
    "    vocab = semantic_models[model]['vocab']\n",
    "    idx = vocab.index(word)\n",
    "    neighbors = list()\n",
    "    for i in np.argsort(sd.cdist([vectors[idx]],vectors,\"cosine\")[0])[1:25]:\n",
    "        val = np.round(sd.cdist([vectors[idx]],[vectors[i]],\"cosine\")[0][0],9)\n",
    "        neighbors.append([vocab[i],val])\n",
    "    return(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distance(word1,word2,model):\n",
    "    vectors = semantic_models[model]['vectors']\n",
    "    idx1 = semantic_models[model]['vocab'].index(word1)\n",
    "    idx2 = semantic_models[model]['vocab'].index(word2)\n",
    "    distance = np.round(sd.cdist([vectors[idx1]],[vectors[idx2]],\"cosine\")[0][0],9)\n",
    "    return(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_distance(\"beautiful\",\"pretty\",1950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_neighbors(\"beautiful\",1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_neighbors(\"cute\",1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "1890\n",
      "1860\n",
      "1990\n",
      "1830\n",
      "1800\n",
      "1980\n",
      "1930\n",
      "1900\n",
      "1970\n",
      "1870\n",
      "1840\n",
      "1960\n",
      "1810\n",
      "1940\n",
      "1910\n",
      "1880\n",
      "1850\n",
      "1820\n",
      "1950\n"
     ]
    }
   ],
   "source": [
    "key_terms = [\"beautiful\",\"cute\",\"ugly\"]\n",
    "\n",
    "outfilejson = \"../../tensors/tensors_all.json\"\n",
    "\n",
    "json_data = dict()\n",
    "json_data['embeddings'] = list()\n",
    "    \n",
    "for model_name in semantic_models.keys():\n",
    "    print(model_name)\n",
    "    tensor_filename = \"../../tensors/\" + \"concepts-\" + str(model_name)\n",
    "    outfiletsv = tensor_filename + '_tensor.tsv'\n",
    "    outfiletsvmeta = tensor_filename + '_metadata.tsv'\n",
    "    outfilejson = tensor_filename + '.json'\n",
    "\n",
    "    \n",
    "    vectors=list()\n",
    "    vocab=list()\n",
    "    \n",
    "    for t in key_terms:\n",
    "        if t in semantic_models[model_name]['vocab']:\n",
    "            nn = get_neighbors(t,model_name)\n",
    "            nn = [x[0] for x in nn]\n",
    "            for n in nn:\n",
    "                vocab.append(n)\n",
    "\n",
    "    # add key terms to list\n",
    "    vocab = vocab + key_terms\n",
    "    vocab = set(vocab)\n",
    "    \n",
    "    with open(outfiletsv, 'wt') as file_vector:\n",
    "        with open(outfiletsvmeta, 'wt',encoding='utf-8') as file_metadata:\n",
    "            for word in vocab:\n",
    "                file_metadata.write(word + '\\n')\n",
    "                idx = semantic_models[model_name]['vocab'].index(word)\n",
    "                vector_row = '\\t'.join(str(x) for x in semantic_models[model_name]['vectors'][idx])\n",
    "                file_vector.write(vector_row + '\\n')\n",
    "    shape = [1000,50]\n",
    "    json_data['embeddings'].append({\n",
    "        'tensorName': str(model_name),\n",
    "        'tensorPath': 'https://raw.githubusercontent.com/jeddobson/vector-space-mappings/master/tensors/concepts-' + str(model_name) + '_tensor.tsv',\n",
    "        'metadataPath': 'https://raw.githubusercontent.com/jeddobson/vector-space-mappings/master/tensors/concepts-' + str(model_name) + '_metadata.tsv',\n",
    "        'tensorShape' : shape\n",
    "    })\n",
    "\n",
    "with open(outfilejson, 'wt') as fp:\n",
    "    json.dump(json_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../../tensors/tensors_all.json\", 'wt') as fp:\n",
    "    json.dump(json_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
