{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import matutils\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load Google News word2vec model\n",
    "google_model = gensim.models.Word2Vec.load_word2vec_format('../models/google-vectors.w2v'\n",
    "                                                           ,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what do we know about this model?\n",
    "vocab_size, dim = google_model.syn0.shape\n",
    "print(\"vocab:\", vocab_size)\n",
    "print(\"depth:\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# useful functions\n",
    "def concept_distance(term1,term2):\n",
    "    distance = 1 - cosine_similarity([google_model[term1],google_model[term2]])\n",
    "    distance = np.round(distance[0][1],5)\n",
    "    return(distance)\n",
    "\n",
    "# return vocab index\n",
    "def vidx(term):\n",
    "    return(google_model.vocab[term].index)\n",
    "\n",
    "# this will return distances from queried term all the way through vocab\n",
    "def get_distances(term):\n",
    "    vectors = google_model.syn0norm[vidx(term)]\n",
    "    dists = dot(google_model.syn0norm, vectors)\n",
    "    best = matutils.argsort(dists, reverse=True)\n",
    "    return(best)\n",
    "\n",
    "# locating binary terms?\n",
    "def get_binary(term):\n",
    "    idx = get_distances(term)[-1:][0]\n",
    "    term2 = google_model.index2word[idx]\n",
    "    return(term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concept cluster: top ranked words from labMT sentiment lexicon\n",
    "\n",
    "#laughter,8.50\n",
    "#happiness,8.44\n",
    "#love,8.42\n",
    "#happy,8.30\n",
    "#laughed,8.26\n",
    "#laugh,8.22\n",
    "#laughing,8.20\n",
    "#excellent,8.18\n",
    "#laughs,8.18\n",
    "#joy,8.16\n",
    "#successful,8.16\n",
    "\n",
    "google_model.most_similar(positive=[\"laughter\",\"happiness\",\"love\",\"happy\",\"laughed\",\n",
    "                                    \"laughing\",\"excellent\",\"laughs\",\"successful\"],topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot top twenty-five neighbors\n",
    "response = google_model.most_similar(positive=[\"laughter\",\"happiness\",\"love\",\"happy\",\"laughed\",\n",
    "                                    \"laughing\",\"excellent\",\"laughs\",\"successful\"],topn=25)\n",
    "neighbor_list=list()\n",
    "words=list()\n",
    "for i in response:\n",
    "    words.append(i[0])\n",
    "    neighbor_list.append(google_model.wv[i[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "dist_matrix = 1 - cosine_similarity(neighbor_list)\n",
    "\n",
    "pos = mds.fit_transform(dist_matrix)\n",
    "\n",
    "xs, ys = pos[:, 0], pos[:, 1]\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "                        \n",
    "plt.clf()\n",
    "plt.title(\"MDS: Neighboring Terms\")\n",
    "plt.style.use('ggplot')\n",
    "plt.scatter(xs, ys, marker = '^')\n",
    "for i, w in enumerate(words):\n",
    "     plt.annotate(w, xy = (xs[i], ys[i]), xytext = (3, 3),\n",
    "            textcoords = 'offset points', ha = 'left', va = 'top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "plot_data = pca.fit_transform(neighbor_list)\n",
    "xs, ys = plot_data[:, 0], plot_data[:, 1]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "plt.clf()\n",
    "plt.title(\"PCA: Neighboring Terms\")\n",
    "plt.style.use('ggplot')\n",
    "plt.scatter(xs, ys, marker = '^')\n",
    "for i, w in enumerate(words):\n",
    "     plt.annotate(w, xy = (xs[i], ys[i]), xytext = (3, 3),\n",
    "            textcoords = 'offset points', ha = 'left', va = 'top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kmeans clustering of terms into three groups (why 3? I don't know)\n",
    "import nltk\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeansClusterer(3, distance=nltk.cluster.util.cosine_distance, \n",
    "                             repeats=25)\n",
    "clusters = kmeans.cluster(neighbor_list, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = list(words)\n",
    "for i, word in enumerate(words):  \n",
    "    print(word + \":\" + str(clusters[i]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=3)\n",
    "kmeans.fit(neighbor_list)\n",
    " \n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    " \n",
    "centers = np.array(centroids)\n",
    "plt.scatter(centers[:,0], centers[:,1], marker=\"x\", color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now extract least happy terms from labMT:\n",
    "#died,1.56\n",
    "#kill,1.56\n",
    "#killed,1.56\n",
    "#cancer,1.54\n",
    "#death,1.54\n",
    "#murder,1.48\n",
    "#terrorism,1.48\n",
    "#rape,1.44\n",
    "#suicide,1.30\n",
    "#terrorist,1.3\n",
    "\n",
    "pos_terms = [\"laughter\",\"happiness\",\"love\",\"happy\",\"laughed\",\n",
    "             \"laughing\",\"excellent\",\"laughs\",\"successful\"]\n",
    "\n",
    "neg_terms = [\"died\",\"kill\",\"killed\",\"cancer\",\"death\",\"murder\",\n",
    "             \"terrorism\",\"rape\",\"suicide\",\"terrorist\"]\n",
    "\n",
    "vectors = [google_model[i] for i in pos_terms + neg_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeansClusterer(2, distance=nltk.cluster.util.cosine_distance, \n",
    "                             repeats=25)\n",
    "clusters = kmeans.cluster(vectors, assign_clusters=True)\n",
    "words = pos_terms + neg_terms\n",
    "for i, word in enumerate(words):  \n",
    "    print(word + \":\" + str(clusters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=2)\n",
    "kmeans.fit(vectors)\n",
    " \n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    " \n",
    "centers = np.array(centroids)\n",
    "plt.scatter(centers[:,0], centers[:,1], marker=\"x\", color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
